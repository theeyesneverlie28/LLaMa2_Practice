{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBNryXyBXCF1jPTewf/L98",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "442add97a2a34817a097d50e4252a203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52bb02ad965c4b7e9e228388c8f1abca",
              "IPY_MODEL_e3aef5e3d8fe4f00b19ef3588c0fec6c",
              "IPY_MODEL_6503e592670f415fb6d83ab664424374"
            ],
            "layout": "IPY_MODEL_53b68189e89c4a77aeb24fe2e0a45aa1"
          }
        },
        "52bb02ad965c4b7e9e228388c8f1abca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c7a56594964fa4a2ef670ce80e2cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_42ea08942a024fa58ae7fe0bbfa516f4",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "e3aef5e3d8fe4f00b19ef3588c0fec6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddcbe8a006274a3db7f2f95cc6ac6bb5",
            "max": 776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fca8172a00ed478c97f739fc8897af90",
            "value": 776
          }
        },
        "6503e592670f415fb6d83ab664424374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_933256c4426948cd96f94c3aa65755e1",
            "placeholder": "​",
            "style": "IPY_MODEL_998129e4590d4524b3eac19630daa03d",
            "value": " 776/776 [00:00&lt;00:00, 33.9kB/s]"
          }
        },
        "53b68189e89c4a77aeb24fe2e0a45aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c7a56594964fa4a2ef670ce80e2cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42ea08942a024fa58ae7fe0bbfa516f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddcbe8a006274a3db7f2f95cc6ac6bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca8172a00ed478c97f739fc8897af90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "933256c4426948cd96f94c3aa65755e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998129e4590d4524b3eac19630daa03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "256e15fb697d461b8c97586fefd4b0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bf3053f861a492a81550a53c1f418f1",
              "IPY_MODEL_a254829e4f504b5e83d53046cbaf8bf0",
              "IPY_MODEL_84b4266ac4fc4c768159c04cf562c212"
            ],
            "layout": "IPY_MODEL_37c9ba68c91740ac903a79a1fa99f421"
          }
        },
        "4bf3053f861a492a81550a53c1f418f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af5f73ca243441b80c5023268016557",
            "placeholder": "​",
            "style": "IPY_MODEL_d986cc7e0e164fb88b2e32c0edee8638",
            "value": "Downloading tokenizer.model: 100%"
          }
        },
        "a254829e4f504b5e83d53046cbaf8bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5943fe52dd6b45e1b8f13bce760a4209",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1a4332e87d74acdbbfe41f925149e9a",
            "value": 499723
          }
        },
        "84b4266ac4fc4c768159c04cf562c212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39065d89183f49d2aa06b10675bcb2cb",
            "placeholder": "​",
            "style": "IPY_MODEL_7613c88a478d4319b6e58b83be2ee9d9",
            "value": " 500k/500k [00:00&lt;00:00, 34.9MB/s]"
          }
        },
        "37c9ba68c91740ac903a79a1fa99f421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2af5f73ca243441b80c5023268016557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d986cc7e0e164fb88b2e32c0edee8638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5943fe52dd6b45e1b8f13bce760a4209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a4332e87d74acdbbfe41f925149e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39065d89183f49d2aa06b10675bcb2cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7613c88a478d4319b6e58b83be2ee9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80a414aff4e044229009dd2c14936296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fe5af6ab8754cbc8dfd689db614fc4b",
              "IPY_MODEL_7ac55a8052034ee8b13ac5fead57dce2",
              "IPY_MODEL_eb189e7e130c478cab84a0b71a6e8ed9"
            ],
            "layout": "IPY_MODEL_0228c1ff76c9400eafa86a9917f84832"
          }
        },
        "3fe5af6ab8754cbc8dfd689db614fc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e055f62f3e2047bbb280409fdc6f775d",
            "placeholder": "​",
            "style": "IPY_MODEL_5cc7db1d53714f55bc541eacbe4041e8",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "7ac55a8052034ee8b13ac5fead57dce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b55bb91f82d4e60a7064fa6b2488050",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_009a175495944c219e1a1d3b3e967aeb",
            "value": 1842767
          }
        },
        "eb189e7e130c478cab84a0b71a6e8ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6441322b0c224aba9f738652fb37f0d8",
            "placeholder": "​",
            "style": "IPY_MODEL_f179b1183a78415fbc6b7362c6e41de4",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 5.78MB/s]"
          }
        },
        "0228c1ff76c9400eafa86a9917f84832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e055f62f3e2047bbb280409fdc6f775d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc7db1d53714f55bc541eacbe4041e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b55bb91f82d4e60a7064fa6b2488050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009a175495944c219e1a1d3b3e967aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6441322b0c224aba9f738652fb37f0d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f179b1183a78415fbc6b7362c6e41de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c74739c13c114d7793054d2ed016e281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e1a38f7c4a244038305fad1d221bddd",
              "IPY_MODEL_956ac32c921c4612a07e496f4041648a",
              "IPY_MODEL_0aeb9dfe72654e09bc78b878afecf7c3"
            ],
            "layout": "IPY_MODEL_501478d6a2e44e918828068a04a9dadd"
          }
        },
        "9e1a38f7c4a244038305fad1d221bddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2f897bc83194f968c00584f8845f649",
            "placeholder": "​",
            "style": "IPY_MODEL_8571a3d97b9d4e298afacdc3f9187f10",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "956ac32c921c4612a07e496f4041648a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a75378d0dc4f46ad0c1530eba27124",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffe10f4f940f4f40afbd0242ebd45593",
            "value": 414
          }
        },
        "0aeb9dfe72654e09bc78b878afecf7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c0da9e3b026455cb758a4a1e42c554a",
            "placeholder": "​",
            "style": "IPY_MODEL_0cabee24cd1d48f4b6d83f5879401f05",
            "value": " 414/414 [00:00&lt;00:00, 18.4kB/s]"
          }
        },
        "501478d6a2e44e918828068a04a9dadd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f897bc83194f968c00584f8845f649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8571a3d97b9d4e298afacdc3f9187f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25a75378d0dc4f46ad0c1530eba27124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe10f4f940f4f40afbd0242ebd45593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c0da9e3b026455cb758a4a1e42c554a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cabee24cd1d48f4b6d83f5879401f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitsangani/Llama-2/blob/main/Llama_2_Q%26A_Using_Langchain_FAISS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Llama 2?**\n",
        "\n",
        "LLaMA 2 model is pretrained and fine-tuned with 2 Trillion 🚀 tokens and 7 to 70 Billion parameters which makes it one of the powerful open source models. It comes in three different model sizes (i.e. 7B, 13B and 70B) with significant improvements over the Llama 1 models, including being trained on 40% more tokens, having a much longer context length (4k tokens 🤯), and using grouped-query attention for fast inference of the 70B model 🔥. It outperforms other open source LLMs on many external benchmarks, including reasoning, coding, proficiency, and knowledge tests."
      ],
      "metadata": {
        "id": "hVziM2pNpQzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Langchain?**\n",
        "\n",
        "LangChain is a powerful, open-source framework designed to help you develop applications powered by a language model, particularly a large language model (LLM). The core idea of the library is that we can “chain” together different components to create more advanced use cases around LLMs. LangChain consists of multiple components from several modules."
      ],
      "metadata": {
        "id": "2EWZ3M-KphCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**What is FAISS (Facebook AI Similarity Search)**\n",
        "\n",
        "FAISS is a library for efficient similarity search and clustering of dense vectors. It can search multimedia documents (e.g. images) in ways that are inefficient or impossible with standard database engines (SQL). It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning.\n",
        "\n"
      ],
      "metadata": {
        "id": "jW5NMzFUprLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Let's get started!**"
      ],
      "metadata": {
        "id": "9KV4oJaSqHL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU transformers accelerate einops langchain xformers bitsandbytes faiss-gpu sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv4x6AUtqUqB",
        "outputId": "e9ea0f25-583d-4978-b4b5-f1b63be7baab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple utility to wrap text in colab before generating a response\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "p9MeScbI0cyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install notebook --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fCw6gyMCPfNv",
        "outputId": "a1998a76-a404-4e7b-c68c-6c35ca9c1cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (6.5.5)\n",
            "Collecting notebook\n",
            "  Downloading notebook-7.0.2-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-server<3,>=2.4.0 (from notebook)\n",
            "  Downloading jupyter_server-2.7.2-py3-none-any.whl (375 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.3/375.3 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-server<3,>=2.22.1 (from notebook)\n",
            "  Downloading jupyterlab_server-2.24.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab<5,>=4.0.2 (from notebook)\n",
            "  Downloading jupyterlab-4.0.5-py3-none-any.whl (9.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook-shim<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from notebook) (0.2.3)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from notebook) (6.3.2)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (23.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (3.1.2)\n",
            "Collecting jupyter-client>=7.4.4 (from jupyter-server<3,>=2.4.0->notebook)\n",
            "  Downloading jupyter_client-8.3.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (5.3.1)\n",
            "Collecting jupyter-events>=0.6.0 (from jupyter-server<3,>=2.4.0->notebook)\n",
            "  Downloading jupyter_events-0.7.0-py3-none-any.whl (18 kB)\n",
            "Collecting jupyter-server-terminals (from jupyter-server<3,>=2.4.0->notebook)\n",
            "  Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (5.9.2)\n",
            "Collecting overrides (from jupyter-server<3,>=2.4.0->notebook)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (23.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (0.17.1)\n",
            "Collecting pyzmq>=24 (from jupyter-server<3,>=2.4.0->notebook)\n",
            "  Downloading pyzmq-25.1.1-cp310-cp310-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (0.17.1)\n",
            "Requirement already satisfied: traitlets>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (5.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook) (1.6.1)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab<5,>=4.0.2->notebook)\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyterlab<5,>=4.0.2->notebook) (5.5.6)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<5,>=4.0.2->notebook)\n",
            "  Downloading jupyter_lsp-2.2.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from jupyterlab<5,>=4.0.2->notebook) (2.0.1)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.22.1->notebook) (2.12.1)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.22.1->notebook)\n",
            "  Downloading json5-0.9.14-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: jsonschema>=4.17.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.22.1->notebook) (4.19.0)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.22.1->notebook) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from async-lru>=1.0.0->jupyterlab<5,>=4.0.2->notebook) (4.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->jupyter-server<3,>=2.4.0->notebook) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook) (0.9.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook) (3.10.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook) (6.0.1)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.8.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.5.0)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.16.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->jupyterlab-server<3,>=2.22.1->notebook) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->jupyterlab-server<3,>=2.22.1->notebook) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->jupyterlab-server<3,>=2.22.1->notebook) (2023.7.22)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->notebook) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (21.2.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyterlab<5,>=4.0.2->notebook) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyterlab<5,>=4.0.2->notebook) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook) (3.0.39)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook) (4.8.0)\n",
            "Collecting fqdn (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting isoduration (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting jsonpointer>1.13 (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting uri-template (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook) (1.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (2.21)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyterlab<5,>=4.0.2->notebook) (0.2.6)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook)\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: json5, uri-template, rfc3986-validator, rfc3339-validator, pyzmq, python-json-logger, overrides, jsonpointer, jedi, fqdn, async-lru, jupyter-server-terminals, jupyter-client, arrow, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, notebook\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 23.2.1\n",
            "    Uninstalling pyzmq-23.2.1:\n",
            "      Successfully uninstalled pyzmq-23.2.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 6.5.5\n",
            "    Uninstalling notebook-6.5.5:\n",
            "      Successfully uninstalled notebook-6.5.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 7.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.2.3 async-lru-2.0.4 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.0 json5-0.9.14 jsonpointer-2.4 jupyter-client-8.3.0 jupyter-events-0.7.0 jupyter-lsp-2.2.0 jupyter-server-2.7.2 jupyter-server-terminals-0.4.4 jupyterlab-4.0.5 jupyterlab-server-2.24.0 notebook-7.0.2 overrides-7.4.0 python-json-logger-2.0.7 pyzmq-25.1.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 uri-template-1.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "zmq"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Initializing the Hugging Face Pipeline**\n",
        "You have to initialize a text-generation pipeline with Hugging Face transformers. The pipeline requires the following three things that you must initialize:\n",
        "\n",
        "A LLM, in this case it will be meta-llama/Llama-2-7b-chat-hf.\n",
        "The respective tokenizer for the model.\n",
        "A stopping criteria object.\n",
        "You have to initialize the model and move it to CUDA-enabled GPU. Using Colab, this can take 5–10 minutes to download and initialize the model.\n",
        "\n",
        "Also, you need to generate an access token to allow downloading the model from Hugging Face in your code. For that, go to your Hugging Face Profile > Settings > Access Token > New Token > Generate a Token. Just copy the token and add it in the below code.\n",
        "\n"
      ],
      "metadata": {
        "id": "ThEvoLUHqejt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda, bfloat16\n",
        "import transformers\n",
        "\n",
        "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
        "\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# set quantization configuration to load large model with less GPU memory\n",
        "# this requires the `bitsandbytes` library\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")\n",
        "\n",
        "# begin initializing HF items, you need an access token\n",
        "hf_auth = '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'\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto',\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "\n",
        "# enable evaluation mode to allow model inference\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded on {device}\")"
      ],
      "metadata": {
        "id": "PVOF87uUqXgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline requires a tokenizer which handles the translation of human readable plaintext to LLM readable token IDs. The Llama 2 7B models were trained using the Llama 2 7B tokenizer, which can be initialized with this code:"
      ],
      "metadata": {
        "id": "tPUo0hMArEIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "442add97a2a34817a097d50e4252a203",
            "52bb02ad965c4b7e9e228388c8f1abca",
            "e3aef5e3d8fe4f00b19ef3588c0fec6c",
            "6503e592670f415fb6d83ab664424374",
            "53b68189e89c4a77aeb24fe2e0a45aa1",
            "46c7a56594964fa4a2ef670ce80e2cfb",
            "42ea08942a024fa58ae7fe0bbfa516f4",
            "ddcbe8a006274a3db7f2f95cc6ac6bb5",
            "fca8172a00ed478c97f739fc8897af90",
            "933256c4426948cd96f94c3aa65755e1",
            "998129e4590d4524b3eac19630daa03d",
            "256e15fb697d461b8c97586fefd4b0ed",
            "4bf3053f861a492a81550a53c1f418f1",
            "a254829e4f504b5e83d53046cbaf8bf0",
            "84b4266ac4fc4c768159c04cf562c212",
            "37c9ba68c91740ac903a79a1fa99f421",
            "2af5f73ca243441b80c5023268016557",
            "d986cc7e0e164fb88b2e32c0edee8638",
            "5943fe52dd6b45e1b8f13bce760a4209",
            "f1a4332e87d74acdbbfe41f925149e9a",
            "39065d89183f49d2aa06b10675bcb2cb",
            "7613c88a478d4319b6e58b83be2ee9d9",
            "80a414aff4e044229009dd2c14936296",
            "3fe5af6ab8754cbc8dfd689db614fc4b",
            "7ac55a8052034ee8b13ac5fead57dce2",
            "eb189e7e130c478cab84a0b71a6e8ed9",
            "0228c1ff76c9400eafa86a9917f84832",
            "e055f62f3e2047bbb280409fdc6f775d",
            "5cc7db1d53714f55bc541eacbe4041e8",
            "2b55bb91f82d4e60a7064fa6b2488050",
            "009a175495944c219e1a1d3b3e967aeb",
            "6441322b0c224aba9f738652fb37f0d8",
            "f179b1183a78415fbc6b7362c6e41de4",
            "c74739c13c114d7793054d2ed016e281",
            "9e1a38f7c4a244038305fad1d221bddd",
            "956ac32c921c4612a07e496f4041648a",
            "0aeb9dfe72654e09bc78b878afecf7c3",
            "501478d6a2e44e918828068a04a9dadd",
            "c2f897bc83194f968c00584f8845f649",
            "8571a3d97b9d4e298afacdc3f9187f10",
            "25a75378d0dc4f46ad0c1530eba27124",
            "ffe10f4f940f4f40afbd0242ebd45593",
            "9c0da9e3b026455cb758a4a1e42c554a",
            "0cabee24cd1d48f4b6d83f5879401f05"
          ]
        },
        "id": "GHkU4fZ-rLUo",
        "outputId": "f4a6965b-704c-4743-d333-86276c659860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "442add97a2a34817a097d50e4252a203"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "256e15fb697d461b8c97586fefd4b0ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80a414aff4e044229009dd2c14936296"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c74739c13c114d7793054d2ed016e281"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to define the stopping criteria of the model. The stopping criteria allows us to specify when the model should stop generating text. If we don’t provide a stopping criteria the model just goes on a bit tangent after answering the initial question."
      ],
      "metadata": {
        "id": "qQqbUxVArQH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_list = ['\\nHuman:', '\\n```\\n']\n",
        "\n",
        "stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n",
        "stop_token_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0Vfz7mArUfU",
        "outputId": "c5274827-8578-4a2b-a0f0-7b3953bb845d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 29871, 13, 29950, 7889, 29901], [1, 29871, 13, 28956, 13]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have to convert these stop token ids into LongTensor objects."
      ],
      "metadata": {
        "id": "oK0mzG31rXmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
        "stop_token_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4sCGri4ra8G",
        "outputId": "824694d9-dff6-4375-c6aa-357df9879a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([    1, 29871,    13, 29950,  7889, 29901], device='cuda:0'),\n",
              " tensor([    1, 29871,    13, 28956,    13], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can do a quick spot check that no <unk> token IDs (0) appear in the stop_token_ids — there are none so we can move on to building the stopping criteria object that will check whether the stopping criteria has been satisfied — meaning whether any of these token ID combinations have been generated."
      ],
      "metadata": {
        "id": "y3GTMSJsr9Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "# define custom stopping criteria object\n",
        "class StopOnTokens(StoppingCriteria):\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop_ids in stop_token_ids:\n",
        "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
      ],
      "metadata": {
        "id": "bYRdC82Gr_By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are ready to initialize the Hugging Face pipeline. There are a few additional parameters that we must define here. Comments are included in the code for further explanation."
      ],
      "metadata": {
        "id": "JxZBVK7osEVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,  # langchain expects the full text\n",
        "    task='text-generation',\n",
        "    # we pass model parameters here too\n",
        "    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
        "    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
        "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
        "    repetition_penalty=1.1  # without this output begins repeating\n",
        ")"
      ],
      "metadata": {
        "id": "srWtuL5SsHxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this code to confirm that everything is working fine."
      ],
      "metadata": {
        "id": "8NBDb6ywsKcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = generate_text(\"What is the meaning of life?\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9vC0V3bsMlV",
        "outputId": "1f0b89b2-c284-43af-f85f-76b058ff4216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"What is the meaning of life?\\n nobody knows for sure, but here are some possible answers:\\n\\n1. To seek happiness and fulfillment: Many people believe that the ultimate goal of life is to find happiness and fulfillment. They believe that one should pursue their passions and interests, and cultivate meaningful relationships with others in order to live a fulfilling life.\\n2. To learn and grow: Others believe that the purpose of life is to learn and grow as individuals. They believe that life is an opportunity to acquire knowledge, develop skills, and become better versions of themselves.\\n3. To make a positive impact: Some people believe that the purpose of life is to make a positive impact on the world. They believe that one should strive to make a difference in the lives of others, whether through acts of kindness, volunteering, or working to make the world a better place.\\n4. To seek spiritual enlightenment: Many religious and philosophical traditions believe that the purpose of life is to seek spiritual enlightenment or union with a higher power. They believe that life is a journey towards this ultimate goal, and that one should cultivate virtues such as compassion, humility, and self-discipline in order to achieve it.\\n5. To leave a lasting legacy: Some people believe that the purpose of life is to leave a lasting legacy that will outlast them. They believe that one should strive to create something that will endure beyond their own lifetimes, whether through artistic expression, scientific discovery, or other forms of creative expression.\\n6. To simply exist: Finally, some people believe that the purpose of life is simply to exist. They believe that life is a precious gift, and that the mere fact of being alive is enough to give one's life meaning and purpose.\\nOf course, these are just a few possible answers to the question of what the meaning of life is. Ultimately, each person must come up with their own answer based on their own beliefs, values, and experiences.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFWCysA_tvaF",
        "outputId": "bb99ecf1-e3bd-4390-983c-a4cba81544ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the meaning of life?\n",
            " nobody knows for sure, but here are some possible answers:\n",
            "\n",
            "1. To seek happiness and fulfillment: Many people believe that the ultimate goal of life is to find happiness and fulfillment. They believe that one should pursue their passions and interests, and cultivate meaningful relationships with others in order to live a fulfilling life.\n",
            "2. To learn and grow: Others believe that the purpose of life is to learn and grow as individuals. They believe that life is an opportunity to acquire knowledge, develop skills, and become better versions of themselves.\n",
            "3. To make a positive impact: Some people believe that the purpose of life is to make a positive impact on the world. They believe that one should strive to make a difference in the lives of others, whether through acts of kindness, volunteering, or working to make the world a better place.\n",
            "4. To seek spiritual enlightenment: Many religious and philosophical traditions believe that the purpose of life is to seek spiritual enlightenment or union with a higher power. They believe that life is a journey towards this ultimate goal, and that one should cultivate virtues such as compassion, humility, and self-discipline in order to achieve it.\n",
            "5. To leave a lasting legacy: Some people believe that the purpose of life is to leave a lasting legacy that will outlast them. They believe that one should strive to create something that will endure beyond their own lifetimes, whether through artistic expression, scientific discovery, or other forms of creative expression.\n",
            "6. To simply exist: Finally, some people believe that the purpose of life is simply to exist. They believe that life is a precious gift, and that the mere fact of being alive is enough to give one's life meaning and purpose.\n",
            "Of course, these are just a few possible answers to the question of what the meaning of life is. Ultimately, each person must come up with their own answer based on their own beliefs, values, and experiences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Implementing HF Pipeline in LangChain**"
      ],
      "metadata": {
        "id": "Up2rvSTsuPCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# checking again that everything is working fine\n",
        "llm(prompt=\"What is the meaning of life?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "3qshi24vuVbf",
        "outputId": "1ba17464-6ac8-4b63-d0da-0549dd313b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n nobody knows for sure, but here are some possible answers:\\n\\n1. To seek happiness and fulfillment: Many people believe that the ultimate goal of life is to find happiness and fulfillment. They believe that one should pursue their passions and interests, and cultivate meaningful relationships with others in order to live a fulfilling life.\\n2. To learn and grow: Others believe that the purpose of life is to learn and grow as individuals. They believe that life is an opportunity to acquire knowledge, develop skills, and become better versions of themselves.\\n3. To make a positive impact: Some people believe that the purpose of life is to make a positive impact on the world. They believe that one should strive to make a difference in the lives of others, whether through acts of kindness, volunteering, or working to make the world a better place.\\n4. To seek spiritual enlightenment: Many religious and philosophical traditions believe that the purpose of life is to seek spiritual enlightenment or union with a higher power. They believe that life is a journey towards this ultimate goal, and that one should cultivate virtues such as compassion, humility, and self-discipline in order to achieve it.\\n5. To leave a lasting legacy: Some people believe that the purpose of life is to leave a lasting legacy that will outlast them. They believe that one should strive to create something that will endure beyond their own lifetimes, whether through artistic expression, scientific discovery, or other forms of creative expression.\\n6. To simply exist: Finally, some people believe that the purpose of life is simply to exist. They believe that life is a precious gift, and that the mere fact of being alive is enough to give one's life meaning and purpose.\\nOf course, these are just a few possible answers to the question of what the meaning of life is. Ultimately, each person must come up with their own answer based on their own beliefs, values, and experiences.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Ingesting Data using Document Loader**\n",
        "\n",
        "You have to ingest data using WebBaseLoader document loader which collects data by scraping webpages. In this case, you will be collecting data from Meta's documentation website.\n"
      ],
      "metadata": {
        "id": "YWULiZc8ul8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "web_links = [\n",
        "\"https://ai.meta.com/\",\n",
        "\"https://ai.meta.com/research/\",\n",
        "\"https://ai.meta.com/blog/\",\n",
        "\"https://ai.meta.com/resources/\",\n",
        "\"https://ai.meta.com/about/\",\n",
        "\"https://ai.meta.com/research/\",\n",
        "\"https://ai.meta.com/blog/\",\n",
        "\"https://ai.meta.com/resources/\",\n",
        "\"https://ai.meta.com/about/\",\n",
        "\"https://ai.meta.com/resources/models-and-libraries/llama-downloads/\",\n",
        "\"https://ai.meta.com/llama/#inside-the-model\",\n",
        "\"https://ai.meta.com/llama/#partnerships\",\n",
        "\"https://ai.meta.com/llama/#responsibility\",\n",
        "\"https://ai.meta.com/llama/#download-the-model\",\n",
        "\"https://ai.meta.com/llama/#resources\",\n",
        "\"https://ai.meta.com/resources/models-and-libraries/llama/\",\n",
        "\"https://ai.meta.com/llama/responsible-use-guide/\",\n",
        "\"https://ai.meta.com/llama/open-innovation-ai-research-community/\",\n",
        "\"https://ai.meta.com/llama/llama-impact-challenge/\",\n",
        "\"https://ai.meta.com/llama/llama-impact-challenge/\",\n",
        "\"https://about.fb.com/news/2023/06/generative-ai-community-forum/\",\n",
        "\"https://www.facebook.com/privacy/policy/?entry_point=data_policy_redirect&entry=0\",\n",
        "\"https://ai.meta.com/resources/models-and-libraries/llama-downloads/\",\n",
        "\"https://ai.meta.com/resources/models-and-libraries/llama/\",\n",
        "\"https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/\",\n",
        "\"https://ai.meta.com/blog/llama-2/\",\n",
        "\"https://ai.meta.com/llama/responsible-use-guide/\",\n",
        "\"https://ai.meta.com/llama/open-innovation-ai-research-community/\",\n",
        "\"https://ai.meta.com/about\",\n",
        "\"https://ai.meta.com/about\",\n",
        "\"https://ai.facebook.com/results/?content_types%5B0%5D=person&sort_by=random\",\n",
        "\"https://www.metacareers.com/jobs/?is_leadership=0&sub_teams[0]=Artificial%20Intelligence&is_in_page=0\",\n",
        "\"https://ai.meta.com/events\",\n",
        "\"https://ai.meta.com/blog\",\n",
        "\"https://ai.meta.com/research\",\n",
        "\"https://ai.meta.com/infrastructure\",\n",
        "\"https://ai.meta.com/blog\",\n",
        "\"https://ai.meta.com/resources\",\n",
        "\"https://ai.meta.com/responsible-ai\",\n",
        "\"https://ai.meta.com/responsible-ai\",\n",
        "\"https://ai.meta.com/subscribe\",\n",
        "\"https://ai.meta.com/subscribe\",\n",
        "\"https://www.facebook.com/MetaAI/\",\n",
        "\"https://twitter.com/MetaAI/\",\n",
        "\"https://www.linkedin.com/showcase/metaai/\",\n",
        "\"https://www.youtube.com/@FacebookAI\",\n",
        "\"https://ai.meta.com/about\",\n",
        "\"https://ai.meta.com/about\",\n",
        "\"https://ai.facebook.com/results/?content_types%5B0%5D=person&sort_by=random\",\n",
        "\"https://www.metacareers.com/jobs/?is_leadership=0&sub_teams[0]=Artificial%20Intelligence&is_in_page=0\",\n",
        "\"https://ai.meta.com/events\",\n",
        "\"https://ai.meta.com/blog\",\n",
        "\"https://ai.meta.com/research\",\n",
        "\"https://ai.meta.com/infrastructure\",\n",
        "\"https://ai.meta.com/blog\",\n",
        "\"https://ai.meta.com/resources\",\n",
        "\"https://ai.meta.com/responsible-ai\",\n",
        "\"https://ai.meta.com/responsible-ai\",\n",
        "\"https://ai.meta.com/subscribe\",\n",
        "\"https://ai.meta.com/subscribe\",\n",
        "\"https://www.facebook.com/MetaAI/\",\n",
        "\"https://twitter.com/MetaAI/\",\n",
        "\"https://www.linkedin.com/showcase/metaai/\",\n",
        "\"https://www.youtube.com/@FacebookAI\",\n",
        "\"https://www.facebook.com/about/privacy/\",\n",
        "\"https://www.facebook.com/policies/\",\n",
        "\"https://www.facebook.com/policies/cookies/\",\n",
        "\"https://www.facebook.com/MetaAI/\",\n",
        "\"https://twitter.com/MetaAI/\",\n",
        "\"https://www.linkedin.com/showcase/metaai/\"]\n",
        "\n",
        "loader = WebBaseLoader(web_links)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "HxbHih8ouqCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Splitting in Chunks using Text Splitters**\n",
        "You have to make sure to split the text into small pieces. You will need to initialize RecursiveCharacterTextSplitter and call it by passing the documents."
      ],
      "metadata": {
        "id": "3ejYQ8_7uuK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "ZDOMtJoHu0n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creating Embeddings and Storing in Vector Store**\n",
        "\n",
        "You have to create embeddings for each small chunk of text and store them in the vector store (i.e. FAISS). You will be using all-mpnet-base-v2 Sentence Transformer to convert all pieces of text in vectors while storing them in the vector store.\n"
      ],
      "metadata": {
        "id": "UIa7HEHbu8jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
        "\n",
        "# storing embeddings in the vector store\n",
        "vectorstore = FAISS.from_documents(all_splits, embeddings)"
      ],
      "metadata": {
        "id": "MHLOj8fgvCk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Initializing Chain**\n",
        "You have to initialize ConversationalRetrievalChain. This chain allows you to have a chatbot with memory while relying on a vector store to find relevant information from your document.\n",
        "\n",
        "Additionally, you can return the source documents used to answer the question by specifying an optional parameter i.e. return_source_documents=True when constructing the chain."
      ],
      "metadata": {
        "id": "iAxs3RGOvJhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)"
      ],
      "metadata": {
        "id": "szsqo1gJvOqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do Q&A against your own data!"
      ],
      "metadata": {
        "id": "C2CdY-qevRcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "query = \"What type of llama 2 models are available?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cKqRwhN5vPEp",
        "outputId": "eaa9103c-b9c1-4cc1-b9d1-863aef4cf2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  \n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Two types of models are available in Llama 2: Foundation models and fine-tuned chat models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time your previous question and answer will be included as a chat history which will enable the ability to ask follow up questions."
      ],
      "metadata": {
        "id": "imZaQk4Vvd-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "\n",
        "query = \"Can you explain key principles a developer needs to follow for acceptable use of models?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "xwZSWfQwvhI8",
        "outputId": "2297bee4-ec78-46e2-989e-4d7d584cba8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  \n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  We provide guidelines for developers to build products powered by large language models responsibly in our Responsible Use Guide. It includes best practices and considerations for building products powered by large language models in a responsible manner.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can also show the source of the document that was used to generate the answer\n",
        "print(result['source_documents'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "AknjGPTtvZv8",
        "outputId": "d911a4a7-2a33-487b-9fd5-0dcb682004c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  \n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Report this post\\n                    \\n    \\n\\n\\n\\n\\n \\n\\n\\nWe’re continuing to invest in an array of responsible AI efforts with the release of Llama 2, including the creation of a new Responsible Use Guide for developers which includes best practices and considerations for building products powered by large language models in a responsible manner.\\n\\nDownload the full guide ➡️ https://bit.ly/3qdzRUH\\n\\nThese best practices should be considered holistically because strategies adopted at one level can impact the entire system. The recommendations included in this guide reflect current research on responsible generative AI. We expect these to evolve as the field advances and access to foundation models grows, inviting further innovation on AI safety.\\n \\n\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    408\\n              \\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n        \\n                11 Comments\\n            \\n      \\n\\n\\n\\n\\n\\n\\n      Like\\n    \\n\\n\\n\\n\\n\\n      Comment\\n    \\n\\n\\n\\n\\n\\n      Share', metadata={'source': 'https://www.linkedin.com/showcase/metaai/', 'title': 'Meta AI | LinkedIn', 'description': 'Meta AI | 538,458 followers on LinkedIn. Together with the AI community, we’re pushing boundaries through open science to create a more connected world. | Through open science and collaboration with the AI community, we are pushing the boundaries of artificial intelligence to create a more connected world.  We can’t advance the progress of AI alone, so we actively engage with the AI research and academic communities. Our goal is to advance AI in Infrastructure, Natural Language Processing, Generative AI, Vision, Human-Computer Interaction and many other areas of AI enable the community to build safe and responsible solutions to address some of the world’s greatest challenges.', 'language': 'en'}), Document(page_content='Report this post\\n                    \\n    \\n\\n\\n\\n\\n \\n\\n\\nWe’re continuing to invest in an array of responsible AI efforts with the release of Llama 2, including the creation of a new Responsible Use Guide for developers which includes best practices and considerations for building products powered by large language models in a responsible manner.\\n\\nDownload the full guide ➡️ https://bit.ly/3qdzRUH\\n\\nThese best practices should be considered holistically because strategies adopted at one level can impact the entire system. The recommendations included in this guide reflect current research on responsible generative AI. We expect these to evolve as the field advances and access to foundation models grows, inviting further innovation on AI safety.\\n \\n\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    408\\n              \\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n        \\n                11 Comments\\n            \\n      \\n\\n\\n\\n\\n\\n\\n      Like\\n    \\n\\n\\n\\n\\n\\n      Comment\\n    \\n\\n\\n\\n\\n\\n      Share', metadata={'source': 'https://www.linkedin.com/showcase/metaai/', 'title': 'Meta AI | LinkedIn', 'description': 'Meta AI | 538,458 followers on LinkedIn. Together with the AI community, we’re pushing boundaries through open science to create a more connected world. | Through open science and collaboration with the AI community, we are pushing the boundaries of artificial intelligence to create a more connected world.  We can’t advance the progress of AI alone, so we actively engage with the AI research and academic communities. Our goal is to advance AI in Infrastructure, Natural Language Processing, Generative AI, Vision, Human-Computer Interaction and many other areas of AI enable the community to build safe and responsible solutions to address some of the world’s greatest challenges.', 'language': 'en'}), Document(page_content='Report this post\\n                    \\n    \\n\\n\\n\\n\\n \\n\\n\\nWe’re continuing to invest in an array of responsible AI efforts with the release of Llama 2, including the creation of a new Responsible Use Guide for developers which includes best practices and considerations for building products powered by large language models in a responsible manner.\\n\\nDownload the full guide ➡️ https://bit.ly/3qdzRUH\\n\\nThese best practices should be considered holistically because strategies adopted at one level can impact the entire system. The recommendations included in this guide reflect current research on responsible generative AI. We expect these to evolve as the field advances and access to foundation models grows, inviting further innovation on AI safety.\\n \\n\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    408\\n              \\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n        \\n                11 Comments\\n            \\n      \\n\\n\\n\\n\\n\\n\\n      Like\\n    \\n\\n\\n\\n\\n\\n      Comment\\n    \\n\\n\\n\\n\\n\\n      Share', metadata={'source': 'https://www.linkedin.com/showcase/metaai/', 'title': 'Meta AI | LinkedIn', 'description': 'Meta AI | 538,458 followers on LinkedIn. Together with the AI community, we’re pushing boundaries through open science to create a more connected world. | Through open science and collaboration with the AI community, we are pushing the boundaries of artificial intelligence to create a more connected world.  We can’t advance the progress of AI alone, so we actively engage with the AI research and academic communities. Our goal is to advance AI in Infrastructure, Natural Language Processing, Generative AI, Vision, Human-Computer Interaction and many other areas of AI enable the community to build safe and responsible solutions to address some of the world’s greatest challenges.', 'language': 'en'}), Document(page_content='We also believe an open approach to research and innovation – especially when it comes to transformative AI technologies – is better than leaving the know-how in the hands of a small number of big tech companies. That’s why we’ve released over 1,000 AI models, libraries and data sets for researchers over the last decade so they can benefit from our computing power and pursue research openly and safely. Openness is also crucial to ensuring developers, entrepreneurs and startups can use foundation models built by big companies to create new tools and to enhance the safety of AI through continuous and open innovation.', metadata={'source': 'https://about.fb.com/news/2023/06/generative-ai-community-forum/', 'title': 'Bringing People Together to Inform Decision-Making on Generative AI | Meta', 'description': \"We're launching a Community Forum on Generative AI aimed at producing feedback on the principles people want to see reflected in new AI technologies.\", 'language': 'en-US'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**TBD: Using Streamlit**\n",
        "\n",
        "You have now the capability to do question-answering on your on data using a powerful language model. Additionally, you can further develop it into a chatbot application using Streamlit.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RO2tcx9MvxUq"
      }
    }
  ]
}